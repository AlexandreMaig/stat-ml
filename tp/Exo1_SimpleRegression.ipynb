{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE 1 : Utilisation de scikit-learn pour la regression lineaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generation de donnees test\n",
    "n = 100\n",
    "x = np.arange(n)\n",
    "y = np.random.randn(n)*30 + 50. * np.log(1 + np.arange(n))\n",
    "\n",
    "# instanciation de sklearn.linear_model.LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x[:, np.newaxis], y)  # np.newaxis est utilise car x doit etre une matrice 2d avec 'LinearRegression'\n",
    "\n",
    "# representation du resultat\n",
    "fig = plt.figure()\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.plot(x, lr.predict(x[:, np.newaxis]), 'b-')\n",
    "plt.legend(('Data', 'Linear Fit'), loc='lower right')\n",
    "plt.title('Linear regression')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">QUESTION 1.1 :</span> \n",
    "Expliquer ce qu'est *lr* et ce que font *lr.fit* et *lr.predict*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">REPONSE 1.1 :</span> \n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">QUESTION 1.2 :</span> \n",
    "\n",
    "On s'interesse à x=105. En supposant que le model lineaire soit toujours valide pour ce x, quelle valeur corresondante de y vous semble la plus vraisemblable ? \n",
    "\n",
    "On remarquera que les valeurs données pour la prediction doivent être dans un vecteur colonne, ici une matrice 1x1.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">REPONSE 1.2 :</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PARTIE 2 : impact et detection d'outliers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#generation de donnees test\n",
    "n = 10\n",
    "x = np.arange(n)\n",
    "y = 10. + 4.*x + np.random.randn(n)*3. \n",
    "y[9]=y[9]+20\n",
    "\n",
    "# instanciation de sklearn.linear_model.LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(x[:, np.newaxis], y)  # np.newaxis est utilise car x doit etre une matrice 2d avec 'LinearRegression'\n",
    "\n",
    "# representation du resultat\n",
    "\n",
    "print('b_0='+str(lr.intercept_)+' et b_1='+str(lr.coef_[0]))\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(x, y, 'r.')\n",
    "plt.plot(x, lr.predict(x[:, np.newaxis]), 'b-')\n",
    "plt.legend(('Data', 'Linear Fit'), loc='lower right')\n",
    "plt.title('Linear regression')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">QUESTION 2.1 :</span> \n",
    "\n",
    "\n",
    "Remarquons que la ligne 'y[9]=y[9]+20' génere artificiellement une donnée aberrante.\n",
    "\n",
    "Tester l'impact de la donnée aberrante en estimant b_0, b_1 et s^2 sur \n",
    "- 5 jeux de données générés comme dans la cellule précédente et\n",
    "- 5 autres jeux aussi générés suivant cette méthode, mais sans la données aberrant (simplement ne pas executer la ligne y[9]=y[9]+20).\n",
    "\n",
    "On remarque que $\\beta_0 = 10$, $\\beta_1 = 4$ et $\\sigma=3$ dans les données simulees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">REPONSE 2.1 :</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">QUESTIONS 2.2 :</span> \n",
    "\n",
    "#### <span style=\"color:blue\">QUESTION 2.2.a :</span> \n",
    "Pour chaque variable i, calculez les profils des résidus $e_{(i)j}=y_j - \\hat{y_{(i)j}}$ pour tous les j, où  \\hat{y_{(i)j}} est l'estimation de y_j à partir d'un modele  linéaire appris sans l'observation i.\n",
    "#### <span style=\"color:blue\">QUESTION 2.2.b :</span> \n",
    "En quoi le profil des e_{(i)j} est différent pour i=9 que pour les autres i\n",
    "#### <span style=\"color:blue\">QUESTION 2.2.c :</span> \n",
    "Etendre ces calculs pour définir la distance de Cook de chaque variable i\n",
    "\n",
    "AIDE : pour enlever un élement 'i' de 'x' ou 'y', utiliser x_del_i=np.delete(x,i) et y_del_i=np.delete(y,i) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-> regeneration de donnees biaisees \n",
    "n = 10\n",
    "x = np.arange(n)\n",
    "y = 10. + 4.*x + np.random.randn(n)*3. \n",
    "y[9]=y[9]+20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">REPONSE 2.2.a :</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">REPONSE 2.2.b :</span> \n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color:blue\">REPONSE 2.2.c :</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PARTIE 3 : Vers la regression linéaire multiple et optimisation\n",
    "\n",
    "On considère que l'on connait les notes sur une année de n élèves dans p matières, ainsi que leurs notes à un concours en fin d'annee. L'année suivante, on  se demande si on ne pourrait pas prédire la note des étudiants au concours en fonction de leurs notes annuelle afin d'estimer leurs chances de réussite au concours.\n",
    "\n",
    "\n",
    "On va resoudre le problème à l'aide de la régression linéaire en dimension p>1 sans utiliser scikit-learn. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">QUESTION 3.1 :</span> \n",
    "\n",
    "A l'aide de la fonction 'SimulateObservations', simulez un jeu de donnees d'apprentissage [X_l,y_l] avec 30 observations et un jeu de test [X_t,y_t] avec 10 observations. Les observations seront en dimension p=10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SimulateObservations(n_train,n_test,p):\n",
    "  \"\"\"\n",
    "  n_train: number of training obserations to simulate\n",
    "  n_test: number of test obserations to simulate\n",
    "  p: dimension of the observations to simulate\n",
    "  \"\"\"\n",
    "  \n",
    "  ObsX_train=20.*np.random.rand(n_train,p)\n",
    "  ObsX_tst=20.*np.random.rand(n_test,p)\n",
    "  \n",
    "  RefTheta=np.random.rand(p)**3\n",
    "  RefTheta=RefTheta/RefTheta.sum()\n",
    "  print(\"The thetas with which the values were simulated is: \"+str(RefTheta))\n",
    "  \n",
    "  ObsY_train=np.dot(ObsX_train,RefTheta.reshape(p,1))+1.5*np.random.randn(n_train,1)\n",
    "  ObsY_tst=np.dot(ObsX_tst,RefTheta.reshape(p,1))+1.5*np.random.randn(n_test,1)\n",
    "  \n",
    "  return [ObsX_train,ObsY_train,ObsX_tst,ObsY_tst,RefTheta]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">REPONSE 3.1 :</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">QUESTION 3.2 :</span> \n",
    "\n",
    "On considere un modele linéaire en dimension p>1 pour mettre en lien les x[i,:] et les y[i], c'est a dire que np.dot(x[i,:],theta_optimal) doit etre le plus proche possible de y[i] sur l'ensemble des observations i. Dans le modèle linéaire multiple, theta_optimal est un vecteur de taille [p,1] qui pondère les différentes variables observées (ici les moyennes dans une matière). Coder alors une fonction qui calcule la moyenne des différences au carré entre ces valeurs en fonction de theta, *i.e.* la mean squared error (MSE) du modèle.\n",
    "\n",
    "### <span style=\"color:blue\">REPONSE 3.2 :</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def CptMSE(X,y_true,theta_test):\n",
    "    \n",
    "    #...\n",
    "    \n",
    "    return MSE\n",
    "\n",
    "\n",
    "theta_test=np.random.rand(p)\n",
    "theta_test=theta_test/theta_test.sum()\n",
    "\n",
    "MSE_test=CptMSE(ObsX_train,ObsY_train,theta_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">QUESTION 3.3 :</span> \n",
    "\n",
    "On va maintenant chercher le theta_test qui minimise cette fonction (il correspondra à theta_optimal), et ainsi résoudre le probleme d'apprentissage de regression lineaire multiple. Utiliser pour cela la fonction minimize de scipy.optimize\n",
    "\n",
    "\n",
    "De manière importante, la recherche des paramètres *theta_optimal* sera effectuée en utilisant les observations d'apprentissage (*ObsX_train* et *ObsY_train* en sortie *SimulateObservations*). La MSE obtenue sur les observations d'apprentissage avec *theta_optimal* sera comparée à celle obtenue avec les observations de test (*ObsX_tst* et *ObsY_tst* en sortie *SimulateObservations*) avec le même *theta_optimal*. Que constatez vous ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <span style=\"color:blue\">REPONSE 3.3 :</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## PARTIE 4 : maximum de vraisemblance\n",
    "\n",
    "### <span style=\"color:blue\">QUESTION 4.1 :</span> \n",
    "\n",
    "Tirer 10 fois une pièce à pile ou face et modéliser les résultats obtenus comme ceux d'une variable aléatoire X qui vaut X_i=0 si on a pile et X_i=1 si on a face.\n",
    "\n",
    "Calculez le maximum de vraisemblance du paramètre p d'un loi de Bernoulli qui modéliserait le problème. Pour y arriver, différentes valeures possibles de p seront testées et le p retenu sera celui qui a la plus grande vraisemblance.\n",
    "\n",
    "\n",
    "- Vérifier empiriquement comment évolue ce maximum de vraisemblance si l'on effectue de plus en plus de tirages\n",
    "- Que se passe-t-il quand il y a trop de tirages ? Représenter la log-vraisemblance plutot que la vraisemblance dans ce cas.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "NbTirages=10\n",
    "NbPiles=#...\n",
    "NbFaces=NbTirages-NbPiles\n",
    "\n",
    "\n",
    "PossibleValuesForP=np.linspace(0,1,100)\n",
    "\n",
    "CorrespondingLikelihood= #...\n",
    "\n",
    "plt.plot(PossibleValuesForP,CorrespondingLikelihood)\n",
    "plt.show()\n",
    "\n",
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### <span style=\"color:blue\">QUESTION 4.2 :</span> \n",
    "\n",
    "\n",
    "Vérifier empiriquement comment évolue ce maximum de vraisemblance si l'on effectue de plus en plus de tirages. Pour éviter de tirer des centaines de fois à pile ou face, vous pourrez juste modifier *NbTirages¨et *NbPiles* dans le code, puis voir le comportement de la courbe *plt.plot(PossibleValuesForP,CorrespondingLikelihood)*.\n",
    "\n",
    "\n",
    "### <span style=\"color:blue\">REPONSE 4.2 :</span> \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### <span style=\"color:blue\">QUESTION 4.3 :</span> \n",
    "\n",
    "\n",
    "Que se passe-t-il quand il y a trop de tirages ? Représenter la log-vraisemblance plutot que la vraisemblance dans ce cas.\n",
    "\n",
    "### <span style=\"color:blue\">REPONSE 4.3 :</span> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
